{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4RnlALYiTfX"
   },
   "source": [
    "\n",
    "<h1 style=\"text-align:center\">Neural Network Assignment</h1>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align: right;\">By Aryan Gupta</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "deqY5veipVHN"
   },
   "outputs": [],
   "source": [
    "# importing packages\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"runs/mnist_SGD\")# device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# hyperparameters\n",
    "input_size = 28*28 #784\n",
    "hidden_size = 250\n",
    "num_of_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate =0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "cqsq5YQV9Ywn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_hfrnew39o5k",
    "outputId": "b69026b9-19b5-4b49-a791-4575f29ff920"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label       0\n",
       "pixel0      0\n",
       "pixel1      0\n",
       "pixel2      0\n",
       "pixel3      0\n",
       "           ..\n",
       "pixel779    0\n",
       "pixel780    0\n",
       "pixel781    0\n",
       "pixel782    0\n",
       "pixel783    0\n",
       "Length: 785, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "zzCr_cY8G7e8",
    "outputId": "c7f91ff9-d01d-4ffe-91a1-e2d9f44a8628"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.456643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219286</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.02019</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.887730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.312890</td>\n",
       "      <td>4.633819</td>\n",
       "      <td>3.274488</td>\n",
       "      <td>1.75987</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>0.414264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\n",
       "count  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
       "mean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel6   pixel7   pixel8  ...      pixel774      pixel775  \\\n",
       "count  42000.0  42000.0  42000.0  ...  42000.000000  42000.000000   \n",
       "mean       0.0      0.0      0.0  ...      0.219286      0.117095   \n",
       "std        0.0      0.0      0.0  ...      6.312890      4.633819   \n",
       "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "max        0.0      0.0      0.0  ...    254.000000    254.000000   \n",
       "\n",
       "           pixel776     pixel777      pixel778      pixel779  pixel780  \\\n",
       "count  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \n",
       "mean       0.059024      0.02019      0.017238      0.002857       0.0   \n",
       "std        3.274488      1.75987      1.894498      0.414264       0.0   \n",
       "min        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "25%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "50%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "75%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "max      253.000000    253.00000    254.000000     62.000000       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  \n",
       "count   42000.0   42000.0   42000.0  \n",
       "mean        0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0  \n",
       "25%         0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0  \n",
       "75%         0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "zH3QVtbwHM1M",
    "outputId": "25263aba-6163-4ffd-a893-56c8d62b2176"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0          1       0       0       0       0       0       0       0       0   \n",
       "1          0       0       0       0       0       0       0       0       0   \n",
       "2          1       0       0       0       0       0       0       0       0   \n",
       "3          4       0       0       0       0       0       0       0       0   \n",
       "4          0       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "41995      0       0       0       0       0       0       0       0       0   \n",
       "41996      1       0       0       0       0       0       0       0       0   \n",
       "41997      7       0       0       0       0       0       0       0       0   \n",
       "41998      6       0       0       0       0       0       0       0       0   \n",
       "41999      9       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "41995       0  ...         0         0         0         0         0   \n",
       "41996       0  ...         0         0         0         0         0   \n",
       "41997       0  ...         0         0         0         0         0   \n",
       "41998       0  ...         0         0         0         0         0   \n",
       "41999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             0         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "41995         0         0         0         0         0  \n",
       "41996         0         0         0         0         0  \n",
       "41997         0         0         0         0         0  \n",
       "41998         0         0         0         0         0  \n",
       "41999         0         0         0         0         0  \n",
       "\n",
       "[42000 rows x 785 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "xl8I4RMep-SJ"
   },
   "outputs": [],
   "source": [
    "# Distorted MNIST Dataset\n",
    "# train data loader\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class DistortedMNIST(Dataset):\n",
    "  def __init__(self):\n",
    "    # data loading\n",
    "    #xy = np.loadtxt(\"Clean_train_mnist.csv\", delimiter=\",\", dtype = np.float32, skiprows=1)\n",
    "    xy = df.to_numpy()\n",
    "    self.x = torch.from_numpy(xy[:,1:].astype(np.float32)).view(-1, 1, 28,28)\n",
    "    self.y = torch.from_numpy(xy[:,0]) # n_samples,1\n",
    "    self.num_of_samples = xy.shape[0]\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    # dataset[0]\n",
    "    return self.x[index], self.y[index]\n",
    "  def __len__(self):\n",
    "    # len(dataset) \n",
    "    return self.num_of_samples\n",
    "\n",
    "train_datasets = DistortedMNIST()\n",
    "\n",
    "# test dataset formulation class\n",
    "class DistortedMNIST_test(Dataset):\n",
    "  # implement init with self\n",
    "  def __init__(self):\n",
    "    # data loading\n",
    "    x = np.loadtxt(\"/content/test.csv\", delimiter=\",\", dtype = np.float32, skiprows=1)\n",
    "    self.x = torch.from_numpy(x).view(-1, 1, 28,28)\n",
    "    self.num_of_samples = x.shape[0]\n",
    "  def __len__(self):\n",
    "    # len(dataset) \n",
    "    return self.num_of_samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "RnS79jdcwtwS"
   },
   "outputs": [],
   "source": [
    "train_datasets = DistortedMNIST()\n",
    "#test_datasets = DistortedMNIST_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T-GUWiJO47Rd",
    "outputId": "934d081f-1719-41e2-aa07-037ea571ab66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000\n"
     ]
    }
   ],
   "source": [
    "print(train_datasets.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M3EqHL1xpY4-",
    "outputId": "8a7efbd0-fd31-4354-ae25-8c634f4adc88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_datasets, batch_size=batch_size, shuffle=True)\n",
    "#test_loader = torch.utils.data.DataLoader(dataset=test_datasets, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "examples = iter(train_loader)\n",
    "samples, labels = examples.next()\n",
    "print(samples.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "id": "PM_XajkYpZlv",
    "outputId": "7a426888-6540-4a20-d6a6-f13a175bb9ce"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.imshow(samples[i][0], cmap=\"gray\")\n",
    "  plt.show()\n",
    "image_grid = torchvision.utils.make_grid(samples)\n",
    "writer.add_image('mnist_images', image_grid)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Defining the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the neural network\n",
    "class NeuralNetwork(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, num_classes):\n",
    "    super(NeuralNetwork, self).__init__()\n",
    "    self.l1 = nn.Linear(input_size, hidden_size)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "  def forward(self, x):\n",
    "    out = self.l1(x)\n",
    "    out = self.relu(out)\n",
    "    out = self.l2(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With SGD:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training (Loss and Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/5, step 64/420,Training accuracy on a sample: 94.0, loss = 0.7944\n",
      "epoch 1/5, step 128/420,Training accuracy on a sample: 98.0, loss = 0.2563\n",
      "epoch 1/5, step 192/420,Training accuracy on a sample: 95.0, loss = 0.2968\n",
      "epoch 1/5, step 256/420,Training accuracy on a sample: 95.0, loss = 0.2941\n",
      "epoch 1/5, step 320/420,Training accuracy on a sample: 93.0, loss = 0.4512\n",
      "epoch 1/5, step 384/420,Training accuracy on a sample: 92.0, loss = 0.6557\n",
      "epoch 2/5, step 64/420,Training accuracy on a sample: 95.0, loss = 0.2792\n",
      "epoch 2/5, step 128/420,Training accuracy on a sample: 97.0, loss = 0.1716\n",
      "epoch 2/5, step 192/420,Training accuracy on a sample: 98.0, loss = 0.1162\n",
      "epoch 2/5, step 256/420,Training accuracy on a sample: 97.0, loss = 0.3267\n",
      "epoch 2/5, step 320/420,Training accuracy on a sample: 96.0, loss = 0.2258\n",
      "epoch 2/5, step 384/420,Training accuracy on a sample: 97.0, loss = 0.1622\n",
      "epoch 3/5, step 64/420,Training accuracy on a sample: 96.0, loss = 0.2636\n",
      "epoch 3/5, step 128/420,Training accuracy on a sample: 97.0, loss = 0.2068\n",
      "epoch 3/5, step 192/420,Training accuracy on a sample: 99.0, loss = 0.1756\n",
      "epoch 3/5, step 256/420,Training accuracy on a sample: 98.0, loss = 0.1945\n",
      "epoch 3/5, step 320/420,Training accuracy on a sample: 96.0, loss = 0.2198\n",
      "epoch 3/5, step 384/420,Training accuracy on a sample: 99.0, loss = 0.1195\n",
      "epoch 4/5, step 64/420,Training accuracy on a sample: 98.0, loss = 0.1436\n",
      "epoch 4/5, step 128/420,Training accuracy on a sample: 100.0, loss = 0.0677\n",
      "epoch 4/5, step 192/420,Training accuracy on a sample: 97.0, loss = 0.1337\n",
      "epoch 4/5, step 256/420,Training accuracy on a sample: 99.0, loss = 0.1758\n",
      "epoch 4/5, step 320/420,Training accuracy on a sample: 99.0, loss = 0.0627\n",
      "epoch 4/5, step 384/420,Training accuracy on a sample: 99.0, loss = 0.1594\n",
      "epoch 5/5, step 64/420,Training accuracy on a sample: 100.0, loss = 0.0445\n",
      "epoch 5/5, step 128/420,Training accuracy on a sample: 99.0, loss = 0.0601\n",
      "epoch 5/5, step 192/420,Training accuracy on a sample: 99.0, loss = 0.0298\n",
      "epoch 5/5, step 256/420,Training accuracy on a sample: 99.0, loss = 0.1154\n",
      "epoch 5/5, step 320/420,Training accuracy on a sample: 99.0, loss = 0.0966\n",
      "epoch 5/5, step 384/420,Training accuracy on a sample: 99.0, loss = 0.0974\n"
     ]
    }
   ],
   "source": [
    "model_SGD = NeuralNetwork(input_size, hidden_size, num_of_classes)\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_SGD.parameters(), lr = learning_rate)\n",
    "\n",
    "# for tensorboard\n",
    "samples = samples.reshape(-1, 28*28).to(device)\n",
    "writer.add_graph(model_SGD, samples)\n",
    "\n",
    "# training loops\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "  for i,(images, labels) in enumerate(train_loader):\n",
    "    # 100, 1, 28, 28\n",
    "    # 100, 784\n",
    "    images = images.reshape(-1, 28*28).to(device)\n",
    "    labels = labels.long().to(device)\n",
    "\n",
    "    # forward\n",
    "    output = model_SGD(images)\n",
    "    loss = criterion(output, labels)\n",
    "\n",
    "    # backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (i+1)%64 == 0:\n",
    "      with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        output= model_SGD(images)\n",
    "        a, predictions = torch.max(output,1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions==labels).sum().item()\n",
    "        train_accuracy = 100.0 *(n_correct/ n_samples)\n",
    "        print(f\"epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps},Training accuracy on a sample: {train_accuracy}, loss = {loss.item():.4f}\")\n",
    "        writer.add_scalar('training loss', loss.item(), epoch*n_total_steps + i)\n",
    "        writer.add_scalar('training accuracy', train_accuracy, epoch*n_total_steps + i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing accuracy :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/5, step 64/420,Testing accuracy on a sample: 95.0\n",
      "epoch 1/5, step 128/420,Testing accuracy on a sample: 99.0\n",
      "epoch 1/5, step 192/420,Testing accuracy on a sample: 100.0\n",
      "epoch 1/5, step 256/420,Testing accuracy on a sample: 97.0\n",
      "epoch 1/5, step 320/420,Testing accuracy on a sample: 95.0\n",
      "epoch 1/5, step 384/420,Testing accuracy on a sample: 99.0\n",
      "epoch 2/5, step 64/420,Testing accuracy on a sample: 98.0\n",
      "epoch 2/5, step 128/420,Testing accuracy on a sample: 98.0\n",
      "epoch 2/5, step 192/420,Testing accuracy on a sample: 99.0\n",
      "epoch 2/5, step 256/420,Testing accuracy on a sample: 97.0\n",
      "epoch 2/5, step 320/420,Testing accuracy on a sample: 98.0\n",
      "epoch 2/5, step 384/420,Testing accuracy on a sample: 97.0\n",
      "epoch 3/5, step 64/420,Testing accuracy on a sample: 99.0\n",
      "epoch 3/5, step 128/420,Testing accuracy on a sample: 98.0\n",
      "epoch 3/5, step 192/420,Testing accuracy on a sample: 100.0\n",
      "epoch 3/5, step 256/420,Testing accuracy on a sample: 99.0\n",
      "epoch 3/5, step 320/420,Testing accuracy on a sample: 99.0\n",
      "epoch 3/5, step 384/420,Testing accuracy on a sample: 96.0\n",
      "epoch 4/5, step 64/420,Testing accuracy on a sample: 98.0\n",
      "epoch 4/5, step 128/420,Testing accuracy on a sample: 98.0\n",
      "epoch 4/5, step 192/420,Testing accuracy on a sample: 99.0\n",
      "epoch 4/5, step 256/420,Testing accuracy on a sample: 98.0\n",
      "epoch 4/5, step 320/420,Testing accuracy on a sample: 99.0\n",
      "epoch 4/5, step 384/420,Testing accuracy on a sample: 97.0\n",
      "epoch 5/5, step 64/420,Testing accuracy on a sample: 98.0\n",
      "epoch 5/5, step 128/420,Testing accuracy on a sample: 99.0\n",
      "epoch 5/5, step 192/420,Testing accuracy on a sample: 99.0\n",
      "epoch 5/5, step 256/420,Testing accuracy on a sample: 97.0\n",
      "epoch 5/5, step 320/420,Testing accuracy on a sample: 96.0\n",
      "epoch 5/5, step 384/420,Testing accuracy on a sample: 97.0\n"
     ]
    }
   ],
   "source": [
    "# testing accuracy on the sample\n",
    "for epoch in range(num_epochs):\n",
    "  for i,(images, labels) in enumerate(train_loader):\n",
    "    images = images.reshape(-1, 28*28).to(device)\n",
    "    labels = labels.long().to(device)\n",
    "    output = model_SGD(images)\n",
    "    if (i+1)%64 == 0:\n",
    "      with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        output= model_SGD(images)\n",
    "        a, predictions = torch.max(output,1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions==labels).sum().item()\n",
    "        test_accuracy = 100.0 *(n_correct/ n_samples)\n",
    "        print(f\"epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps},Testing accuracy on a sample: {test_accuracy}\")\n",
    "        writer.add_scalar('testing accuracy', test_accuracy, epoch*n_total_steps + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Training (Loss and Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3/5, step 384/420,Training accuracy on a sample: 95.0, loss = 0.3069\n",
      "epoch 4/5, step 64/420,Training accuracy on a sample: 100.0, loss = 0.0430\n",
      "epoch 4/5, step 128/420,Training accuracy on a sample: 96.0, loss = 0.2503\n",
      "epoch 4/5, step 192/420,Training accuracy on a sample: 96.0, loss = 0.1387\n",
      "epoch 4/5, step 256/420,Training accuracy on a sample: 98.0, loss = 0.0892\n",
      "epoch 4/5, step 320/420,Training accuracy on a sample: 100.0, loss = 0.0298\n",
      "epoch 4/5, step 384/420,Training accuracy on a sample: 98.0, loss = 0.1306\n",
      "epoch 5/5, step 64/420,Training accuracy on a sample: 98.0, loss = 0.1575\n",
      "epoch 5/5, step 128/420,Training accuracy on a sample: 99.0, loss = 0.0569\n",
      "epoch 5/5, step 192/420,Training accuracy on a sample: 99.0, loss = 0.1325\n",
      "epoch 5/5, step 256/420,Training accuracy on a sample: 98.0, loss = 0.0779\n",
      "epoch 5/5, step 320/420,Training accuracy on a sample: 98.0, loss = 0.0486\n",
      "epoch 5/5, step 384/420,Training accuracy on a sample: 99.0, loss = 0.1050\n",
      "epoch 1/5, step 64/420,Training accuracy on a sample: 86.0, loss = 1.6140\n",
      "epoch 1/5, step 128/420,Training accuracy on a sample: 92.0, loss = 0.7686\n",
      "epoch 1/5, step 192/420,Training accuracy on a sample: 97.0, loss = 0.4050\n",
      "epoch 1/5, step 256/420,Training accuracy on a sample: 98.0, loss = 0.2424\n",
      "epoch 1/5, step 320/420,Training accuracy on a sample: 93.0, loss = 0.3363\n",
      "epoch 1/5, step 384/420,Training accuracy on a sample: 97.0, loss = 0.1495\n",
      "epoch 2/5, step 64/420,Training accuracy on a sample: 97.0, loss = 0.1578\n",
      "epoch 2/5, step 128/420,Training accuracy on a sample: 97.0, loss = 0.1474\n",
      "epoch 2/5, step 192/420,Training accuracy on a sample: 97.0, loss = 0.1198\n",
      "epoch 2/5, step 256/420,Training accuracy on a sample: 99.0, loss = 0.0626\n",
      "epoch 2/5, step 320/420,Training accuracy on a sample: 95.0, loss = 0.2649\n",
      "epoch 2/5, step 384/420,Training accuracy on a sample: 96.0, loss = 0.2057\n",
      "epoch 3/5, step 64/420,Training accuracy on a sample: 97.0, loss = 0.1573\n",
      "epoch 3/5, step 128/420,Training accuracy on a sample: 99.0, loss = 0.1431\n",
      "epoch 3/5, step 192/420,Training accuracy on a sample: 99.0, loss = 0.0686\n",
      "epoch 3/5, step 256/420,Training accuracy on a sample: 95.0, loss = 0.1988\n",
      "epoch 3/5, step 320/420,Training accuracy on a sample: 99.0, loss = 0.0603\n",
      "epoch 3/5, step 384/420,Training accuracy on a sample: 94.0, loss = 0.2156\n",
      "epoch 4/5, step 64/420,Training accuracy on a sample: 99.0, loss = 0.0496\n",
      "epoch 4/5, step 128/420,Training accuracy on a sample: 100.0, loss = 0.1270\n",
      "epoch 4/5, step 192/420,Training accuracy on a sample: 100.0, loss = 0.0469\n",
      "epoch 4/5, step 256/420,Training accuracy on a sample: 99.0, loss = 0.0907\n",
      "epoch 4/5, step 320/420,Training accuracy on a sample: 99.0, loss = 0.0550\n",
      "epoch 4/5, step 384/420,Training accuracy on a sample: 98.0, loss = 0.1043\n",
      "epoch 5/5, step 64/420,Training accuracy on a sample: 100.0, loss = 0.0061\n",
      "epoch 5/5, step 128/420,Training accuracy on a sample: 97.0, loss = 0.1577\n",
      "epoch 5/5, step 192/420,Training accuracy on a sample: 98.0, loss = 0.0692\n",
      "epoch 5/5, step 256/420,Training accuracy on a sample: 98.0, loss = 0.0921\n",
      "epoch 5/5, step 320/420,Training accuracy on a sample: 100.0, loss = 0.0371\n",
      "epoch 5/5, step 384/420,Training accuracy on a sample: 98.0, loss = 0.0755\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(\"runs/MNIST_Adam\")\n",
    "model_Adam = NeuralNetwork(input_size, hidden_size, num_of_classes)\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_Adam.parameters(), lr = learning_rate)\n",
    "\n",
    "# training loops\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "  for i,(images, labels) in enumerate(train_loader):\n",
    "    # 100, 1, 28, 28\n",
    "    # 100, 784\n",
    "    images = images.reshape(-1, 28*28).to(device)\n",
    "    labels = labels.long().to(device)\n",
    "\n",
    "    # forward\n",
    "    output = model_Adam(images)\n",
    "    loss = criterion(output, labels)\n",
    "\n",
    "    # backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (i+1)%64 == 0:\n",
    "      with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        output= model_Adam(images)\n",
    "        a, predictions = torch.max(output,1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions==labels).sum().item()\n",
    "        train_accuracy = 100.0 *(n_correct/ n_samples)\n",
    "        print(f\"epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps},Training accuracy on a sample: {train_accuracy}, loss = {loss.item():.4f}\")\n",
    "        writer.add_scalar('training loss', loss.item(), epoch*n_total_steps + i)\n",
    "        writer.add_scalar('training accuracy', train_accuracy, epoch*n_total_steps + i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Testing accuracy :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/5, step 64/420,Testing accuracy on a sample: 99.0\n",
      "epoch 1/5, step 128/420,Testing accuracy on a sample: 98.0\n",
      "epoch 1/5, step 192/420,Testing accuracy on a sample: 94.0\n",
      "epoch 1/5, step 256/420,Testing accuracy on a sample: 97.0\n",
      "epoch 1/5, step 320/420,Testing accuracy on a sample: 98.0\n",
      "epoch 1/5, step 384/420,Testing accuracy on a sample: 97.0\n",
      "epoch 2/5, step 64/420,Testing accuracy on a sample: 95.0\n",
      "epoch 2/5, step 128/420,Testing accuracy on a sample: 95.0\n",
      "epoch 2/5, step 192/420,Testing accuracy on a sample: 99.0\n",
      "epoch 2/5, step 256/420,Testing accuracy on a sample: 96.0\n",
      "epoch 2/5, step 320/420,Testing accuracy on a sample: 94.0\n",
      "epoch 2/5, step 384/420,Testing accuracy on a sample: 95.0\n",
      "epoch 3/5, step 64/420,Testing accuracy on a sample: 95.0\n",
      "epoch 3/5, step 128/420,Testing accuracy on a sample: 100.0\n",
      "epoch 3/5, step 192/420,Testing accuracy on a sample: 98.0\n",
      "epoch 3/5, step 256/420,Testing accuracy on a sample: 97.0\n",
      "epoch 3/5, step 320/420,Testing accuracy on a sample: 98.0\n",
      "epoch 3/5, step 384/420,Testing accuracy on a sample: 96.0\n",
      "epoch 4/5, step 64/420,Testing accuracy on a sample: 96.0\n",
      "epoch 4/5, step 128/420,Testing accuracy on a sample: 96.0\n",
      "epoch 4/5, step 192/420,Testing accuracy on a sample: 97.0\n",
      "epoch 4/5, step 256/420,Testing accuracy on a sample: 97.0\n",
      "epoch 4/5, step 320/420,Testing accuracy on a sample: 93.0\n",
      "epoch 4/5, step 384/420,Testing accuracy on a sample: 99.0\n",
      "epoch 5/5, step 64/420,Testing accuracy on a sample: 98.0\n",
      "epoch 5/5, step 128/420,Testing accuracy on a sample: 99.0\n",
      "epoch 5/5, step 192/420,Testing accuracy on a sample: 98.0\n",
      "epoch 5/5, step 256/420,Testing accuracy on a sample: 97.0\n",
      "epoch 5/5, step 320/420,Testing accuracy on a sample: 97.0\n",
      "epoch 5/5, step 384/420,Testing accuracy on a sample: 98.0\n"
     ]
    }
   ],
   "source": [
    "# testing accuracy on the sample\n",
    "for epoch in range(num_epochs):\n",
    "  for i,(images, labels) in enumerate(train_loader):\n",
    "    images = images.reshape(-1, 28*28).to(device)\n",
    "    labels = labels.long().to(device)\n",
    "    output = model_Adam(images)\n",
    "    if (i+1)%64 == 0:\n",
    "      with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        output= model_Adam(images)\n",
    "        a, predictions = torch.max(output,1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions==labels).sum().item()\n",
    "        train_accuracy = 100.0 *(n_correct/ n_samples)\n",
    "        print(f\"epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps},Testing accuracy on a sample: {train_accuracy}\")\n",
    "        writer.add_scalar('testing accuracy', test_accuracy, epoch*n_total_steps + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for running tenserboard on the terminal, write the following in terminal\n",
    "\n",
    "`tensorboard --logdir=runs`"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled7.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
